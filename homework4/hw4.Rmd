---
title: "Homework 4"
author: "Peyton Kuhlers"
date: "10/15/2020"
output: pdf_document
---

```{r, echo = F}
suppressMessages(library(gbm))
suppressMessages(library(tidyverse))
suppressMessages(library(MLmetrics))

dat <- read.csv("500_Person_Gender_Height_Weight_Index.csv")
```

Question 1
----------
In order to run a glm, I assigned male to 0 and female to 1. I also randomly assigned a training or test set label. I then performed a logistic regression with height and weight as predictors. The accuracy was 0.52 in the test set.
```{r}
set.seed(111)
dat$Gender_num <- ifelse(dat$Gender == "Male", 0, 1)

subsamp <- c(rep("Train",450), rep("Test",50))
scramble <- sample(subsamp, size = 500, replace = F)

dat$set <- scramble

train <- dat[dat$set == "Train",]
test <- dat[dat$set == "Test",]

mod1 <- glm(formula = Gender_num ~ Height + Weight,
            family = "binomial",
            data = train)

summary(mod1)
preds1 <- predict(object = mod1,
                 newdata = test,
                 type = "response")
sum((preds1 > 0.5) == test$Gender_num) /nrow(test)
```

Question 2
----------
I then used a GBM on the train set and then accuracy rose to 0.62 in the test set.
```{r}
mod2 <- gbm(formula = Gender_num ~ Height + Weight,
            distribution = "bernoulli",
            data = train)
summary(mod2)
preds2 <- predict(object = mod2,
                  newdata = test,
                  type = "response")
sum((preds2 > 0.5) == test$Gender_num) / nrow(test)
```

Question 3
----------
Here I filtered the data to only contain 50 males (and all of the females). I then fit a logistic regression model to the new data. Every sample was classified as female -- which actually caused an error in the F1 score calculation as all of the classifications were the same.
```{r}
datMale <- dat %>%
  group_by(Gender) %>%
  filter(Gender == "Male") %>%
  slice_sample(n = 50, replace = F)

filtDat <- dat %>%
  group_by(Gender) %>%
  filter(Gender == "Female") %>%
  bind_rows(., datMale)

mod3 <- glm(Gender_num ~ Height + Weight,
            family = "binomial",
            data = filtDat)
summary(mod3)
preds3 <- predict(mod3, type = "response")
```

Question 4
----------
The ROC curve shows that the best we can do with this model is about a 35% false positive rate, with a perfect true positive rate.
```{r}
roc <- do.call(rbind, Map(function(threshold){
  p <- preds3 > threshold;
  tp <- sum(p[filtDat$Gender_num])/sum(filtDat$Gender_num);
  fp <- sum(p[!filtDat$Gender_num])/sum(!filtDat$Gender_num);
  tibble(threshold=threshold,
         tp=tp,
         fp=fp)
},seq(100)/100))

ggplot(data = roc, aes(x = fp, y = tp)) + geom_line() +
  xlim(0,1) + ylim(0,1) +
  xlab("False Pos") + ylab("True Pos") + labs(title = "ROC curve")
  
```

Question 5
----------
The k-means graph separates the upper half of the data from the lower half of the data. However, looking at a labeled graph of height vs weight it is clear that the two clusters do not represent clusters of males a females. They seem to just separate big and tall people from small and short people.
```{r}
km <- kmeans(data.frame(dat$Height, dat$Weight),centers = 2)

ggplot(dat, aes(x = Height, y = Weight, col = km$cluster)) + geom_point()
ggplot(dat, aes(x = Height, y = Weight, col = Gender)) + geom_point()
```